import React, { useEffect, useRef, useState } from 'react';
import * as tf from '@tensorflow/tfjs';
import '@tensorflow/tfjs-backend-webgl';
import * as poseDetection from '@tensorflow-models/pose-detection';

import { drawPose } from '../utils/drawing';
import { computeFrameMetrics, initAccumulator, pushFrame, summarize, buildReport } from '../utils/gaitMetrics';

const FPS = 30;

// Ø¥Ø¶Ø§ÙØ© onKpis ÙƒÙ€ prop
export default function PoseAnalyzer({ onReport, onKpis, onKneeDataUpdate }) {
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const detectorRef = useRef(null);
  const rafRef = useRef(null);
  const accRef = useRef(initAccumulator());

  const [ready, setReady] = useState(false);
  const [running, setRunning] = useState(false);
  const [useCamera, setUseCamera] = useState(true);
  const [camFacing, setCamFacing] = useState('environment');
  const [kpis, setKpis] = useState({ cadence: '-', knees: '-', trunk: '-', symmetry: '-' });
  const [fileURL, setFileURL] = useState(null);

  useEffect(() => {
    (async () => {
      await tf.setBackend('webgl');
      await tf.ready();
      const detectorConfig = { modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING, enableSmoothing: true };
      detectorRef.current = await poseDetection.createDetector(poseDetection.SupportedModels.MoveNet, detectorConfig);
      setReady(true);
      console.log('Detector ready');
    })();

    return () => stopAll();
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, []);

  // Ø¥Ø¶Ø§ÙØ© useEffect Ø¬Ø¯ÙŠØ¯ Ù„ØªÙ…Ø±ÙŠØ± Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø­ÙŠØ© Ù„Ù„Ù…ÙƒÙˆÙ‘Ù† Ø§Ù„Ø£Ø¨
  useEffect(() => {
    if (onKpis) {
        onKpis(kpis);
    }
  }, [kpis, onKpis]);


  async function startCamera() {
    stopAll();
    const constraints = {
      video: {
        width: { ideal: 960 },
        height: { ideal: 540 },
        frameRate: { ideal: FPS },
        facingMode: camFacing
      },
      audio: false
    };
    const stream = await navigator.mediaDevices.getUserMedia(constraints);
    const v = videoRef.current;
    v.srcObject = stream;
    await v.play();
    resizeCanvasToVideo();
  }

  async function loadVideoFile(file) {
    stopAll();
    if (!file) return;
    const url = URL.createObjectURL(file);
    setFileURL(url);
    const v = videoRef.current;
    v.srcObject = null;
    v.src = url;
    v.loop = false;
    await v.play();
    await new Promise((r) => {
      if (v.readyState >= 2) r();
      else v.onloadedmetadata = r;
    });
    resizeCanvasToVideo();
  }

  function resizeCanvasToVideo() {
    const v = videoRef.current, c = canvasRef.current;
    if (!v || !c) return;
    c.width = v.videoWidth;
    c.height = v.videoHeight;

      // Ø§Ø¶Ø¨Ø· Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ­ÙˆÙŠÙ„ ÙÙŠ accumulator (100cm â‰ˆ Ø¹Ø±Ø¶ Ø§Ù„ÙÙŠØ¯ÙŠÙˆ)
  if (accRef.current) {
    accRef.current.pxToCm = v.videoWidth ? (100 / v.videoWidth) : null;
  }
  }

  function stopCameraTracks() {
    const v = videoRef.current;
    const stream = v?.srcObject;
    if (stream) {
      stream.getTracks().forEach(t => t.stop());
      v.srcObject = null;
    }
  }

  function stopAll() {
    if (rafRef.current) cancelAnimationFrame(rafRef.current);
    rafRef.current = null;
    stopCameraTracks();
    setRunning(false);
  }

  async function loop() {
    rafRef.current = requestAnimationFrame(loop);
    await analyzeFrame();
  }

  async function analyzeFrame() {
    const v = videoRef.current;
    const c = canvasRef.current;
    if (!v || !detectorRef.current || v.readyState < 2) return;

      // ğŸ§  ØªØ¹ÙŠÙŠÙ† Ù…Ù‚ÙŠØ§Ø³ Ø«Ø§Ø¨Øª Ù„ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙƒØ³Ù„ Ø¥Ù„Ù‰ Ø³Ù…
  if (accRef.current) {
    accRef.current.pxToCm = 0.1; // ÙƒÙ„ 10 Ø¨ÙƒØ³Ù„ â‰ˆ 1 Ø³Ù… (ÙŠÙ…ÙƒÙ†Ùƒ ØªØ¹Ø¯ÙŠÙ„Ù‡)
  }

  // ğŸ§© Ø¯Ø§Ù„Ø© Ù„ØªÙ†Ø¹ÙŠÙ… Ø§Ù„Ù‚ÙŠÙ… Ù‚Ø¨Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ù„ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø¶Ø¬ÙŠØ¬
  function smoothArray(arr, windowSize = 5) {
    return arr.map((_, i, a) => {
      const slice = a.slice(Math.max(0, i - windowSize), i + windowSize + 1).filter(v => v != null);
      return slice.length ? slice.reduce((s, x) => s + x, 0) / slice.length : null;
    });
  }


    const poses = await detectorRef.current.estimatePoses(v, { flipHorizontal: false });
    const ctx = c.getContext('2d');
    ctx.clearRect(0, 0, c.width, c.height);

    if (poses?.[0]?.keypoints) {
      drawPose(ctx, poses[0].keypoints, 0.45);
      const fm = computeFrameMetrics(poses[0].keypoints);
      pushFrame(accRef.current, fm);

        // ğŸ¦µ ØªÙ†Ø¹ÙŠÙ… Ø¥Ø­Ø¯Ø§Ø«ÙŠØ§Øª Ø§Ù„ÙƒØ§Ø­Ù„ÙŠÙ† Ù‚Ø¨Ù„ Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚Ù…Ù…
  const smoothL = smoothArray(accRef.current.ankleHistL || []);
  const smoothR = smoothArray(accRef.current.ankleHistR || []);

  // ğŸ” Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù‚Ù…Ù… Ø¨Ø¹Ø¯ Ø§Ù„ØªÙ†Ø¹ÙŠÙ… (Ù„Ùˆ Ø¹Ù†Ø¯Ùƒ Ø¯Ø§Ù„Ø© findPeaks Ø¬Ø§Ù‡Ø²Ø© ÙÙŠ gaitMetrics)
  if (typeof findPeaks === "function" && accRef.current) {
    const peaksL = findPeaks(smoothL);
    const peaksR = findPeaks(smoothR);

    // âš™ï¸ Ø­Ø³Ø§Ø¨ Ù…ØªÙˆØ³Ø· Ø·ÙˆÙ„ Ø§Ù„Ø®Ø·ÙˆØ© Ø¨Ø¯Ù‚Ø©
    const avgLeft = calcAverageStepLength(peaksL, accRef.current.pxToCm);
    const avgRight = calcAverageStepLength(peaksR, accRef.current.pxToCm);

    // ğŸ’¡ Ø­Ø³Ø§Ø¨ Ø§Ù„ØªÙ…Ø§Ø«Ù„ Ø¨Ù†Ø³Ø¨Ø© Ù…Ø¦ÙˆÙŠØ© Ø¯Ù‚ÙŠÙ‚Ø©
    const symmetry =
      avgLeft && avgRight
        ? (Math.min(avgLeft, avgRight) / Math.max(avgLeft, avgRight)) * 100
        : 0;

    setKpis(prev => ({
      ...prev,
      leftStepLength: avgLeft ? avgLeft.toFixed(1) : prev.leftStepLength,
      rightStepLength: avgRight ? avgRight.toFixed(1) : prev.rightStepLength,
      strideSymmetry: symmetry ? symmetry.toFixed(1) : prev.strideSymmetry,
    }));
  }


      // Ø¥Ø¶Ø§ÙØ© Ø³Ø¬Ù„ Ø²ÙˆØ§ÙŠØ§ Ø§Ù„Ø±ÙƒØ¨Ø© Ø§Ù„Ø­Ø§Ù„ÙŠØ© Ù„Ù„Ù…ÙƒÙˆÙ‘Ù† Ø§Ù„Ø£Ø¨ (App.jsx)
    const currentKneeData = {
      left: fm.leftKnee,
      right: fm.rightKnee,
      frame: accRef.current.frames // Ø±Ù‚Ù… Ø§Ù„Ø¥Ø·Ø§Ø±
  };
  if (onKneeDataUpdate) { // Ø¯Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø¥Ø±Ø³Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø²ÙˆØ§ÙŠØ§
      onKneeDataUpdate(currentKneeData);
  }

      const s = summarize(accRef.current, FPS);
      setKpis({
        cadence: s.cadence != null ? `${s.cadence}` : '-',
        // Ø¹Ø±Ø¶ Ø£Ù‚ØµÙ‰ Ø§Ù†Ø«Ù†Ø§Ø¡ Ø¥Ø°Ø§ Ù…ØªÙˆÙØ±ØŒ ÙˆØ¥Ù„Ø§ Ø¹Ø±Ø¶ Ø§Ù„Ù…ØªÙˆØ³Ø·
        knees: (s.leftKneeMaxFlexion != null && s.rightKneeMaxFlexion != null)
          ? `${s.leftKneeMaxFlexion.toFixed(0)}Â° / ${s.rightKneeMaxFlexion.toFixed(0)}Â°`
          : (s.leftKneeAvg != null && s.rightKneeAvg != null)
            ? `${s.leftKneeAvg.toFixed(0)}Â° / ${s.rightKneeAvg.toFixed(0)}Â°`
            : '-',
        trunk: (s.maxTrunkLean != null) ? `${s.maxTrunkLean.toFixed(1)}Â°` : (s.trunkLeanAvg != null ? `${s.trunkLeanAvg.toFixed(1)}Â°` : '-'),
        symmetry: s.symmetry != null ? `${s.symmetry.toFixed(0)}%` : '-',
        strideSymmetry: s.strideSymmetry != null ? `${s.strideSymmetry.toFixed(0)}%` : '-',

     // Ø§Ù„Ø­Ù‚ÙˆÙ„ Ø§Ù„Ø¹Ø¯Ø¯ÙŠØ© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© (Ø¨Ø§Ù„Ø³Ù…) Ù„ØªØ³ØªØ®Ø¯Ù…Ù‡Ø§ App.jsx Ù…Ø¨Ø§Ø´Ø±Ø©
  leftStepLength: s.leftStepAvgCm != null ? s.leftStepAvgCm : null,
  rightStepLength: s.rightStepAvgCm != null ? s.rightStepAvgCm : null,
  stepSymmetryPercent: s.stepSymmetryPercent != null ? s.stepSymmetryPercent : null,
});
      
    } else {
    }

    // ğŸ”¹ Ø­Ø³Ø§Ø¨ Ø·ÙˆÙ„ Ø§Ù„Ø®Ø·ÙˆØ© (Ø§Ù„Ù…Ø³Ø§ÙØ© Ø§Ù„Ø£ÙÙ‚ÙŠØ© Ø¨ÙŠÙ† Ø§Ù„Ù‚Ø¯Ù…ÙŠÙ†)
const leftAnkle = poses[0].keypoints.find(p => p.name === "left_ankle");
const rightAnkle = poses[0].keypoints.find(p => p.name === "right_ankle");

if (leftAnkle && rightAnkle) {
  const stepLength = Math.abs(leftAnkle.x - rightAnkle.x); // Ø¨Ø§Ù„Ø¨ÙƒØ³Ù„

  // ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙƒØ³Ù„ Ø¥Ù„Ù‰ Ø³Ù… (ØªÙ‚Ø¯ÙŠØ±ÙŠÙ‹Ø§ Ø­Ø³Ø¨ Ø­Ø¬Ù… Ø§Ù„Ø¥Ø·Ø§Ø±)
  const stepLengthCm = (stepLength / videoRef.current.videoWidth) * 100; 

  // ØªÙ…Ø±ÙŠØ±Ù‡Ø§ Ù„Ù€ App.jsx Ø¹Ø¨Ø± onKpis
  if (onKpis) {
    onKpis({
      cadence: kpis.cadence,
      knees: kpis.knees,
      trunk: kpis.trunk,
      symmetry: kpis.symmetry,
      strideSymmetry: kpis.strideSymmetry,
      leftStepLength: leftAnkle.x < rightAnkle.x ? stepLengthCm : kpis.leftStepLength,
      rightStepLength: rightAnkle.x > leftAnkle.x ? stepLengthCm : kpis.rightStepLength,
    });
  }
  
}

  }

  async function startAnalysis() {
    if (!ready) {
      alert('Ø§Ù„ÙˆØ¬Ù‡ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠ ØºÙŠØ± Ø¬Ø§Ù‡Ø² Ø¨Ø¹Ø¯ØŒ Ø§Ù†ØªØ¸Ø± Ø«ÙˆØ§Ù†ÙŠ Ø«Ù… Ø¬Ø±Ø¨.');
      return;
    }
    accRef.current = initAccumulator();
    if (useCamera) await startCamera();
    else if (fileURL) {
      const v = videoRef.current;
      v.currentTime = 0;
      await v.play();
    } else {
      alert('Ø­Ù…Ù‘Ù„ ÙÙŠØ¯ÙŠÙˆ Ø£Ùˆ ÙØ¹Ù„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ø£ÙˆÙ„Ø§Ù‹.');
      return;
    }

    setRunning(true);
    loop();

    const v = videoRef.current;
    v.onended = () => {
      stopAnalysis();
    };
  }

  function stopAnalysis() {
    if (rafRef.current) cancelAnimationFrame(rafRef.current);
    rafRef.current = null;
    if (useCamera) stopCameraTracks();
    setRunning(false);

    const summary = summarize(accRef.current, FPS);
    const rep = buildReport(summary);
    if (onReport) onReport(rep);
  }

  function toggleFacing() {
    setCamFacing(f => f === 'user' ? 'environment' : 'user');
  }

  function handleFile(e) {
    const file = e.target.files[0];
    if (!file) return;
    loadVideoFile(file);
  }

  return (
    <div>
      {/* ØªÙ… Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù…Ù† Ù‡Ù†Ø§ */}
      <div className="card" style={{ padding: 12 }}>
        <div
          className="card"
          style={{
            padding: '20px',
            backgroundColor: '#1b244d',
            textAlign: 'center',
          }}
        >
          <h3 style={{ marginTop: 0, marginBottom: '5px', fontSize: '1.5em' }}>
            Ø§Ø®ØªØ± Ù…ØµØ¯Ø± Ø§Ù„ÙÙŠØ¯ÙŠÙˆ
          </h3>
          <div className="video-source-buttons" style={{ display: 'flex', justifyContent: 'center', gap: '20px' }}>
            <label
              style={{
                display: 'flex',
                alignItems: 'center',
                justifyContent: 'center',
                gap: '8px',
                width: '160px',
                height: '50px',
                border: '2px solid #90caf9',
                borderRadius: '10px',
                cursor: 'pointer',
              }}
            >
              <input type="radio" checked={useCamera} onChange={() => setUseCamera(true)} />
              Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§
            </label>
            <label
              style={{
                display: 'flex',
                alignItems: 'center',
                justifyContent: 'center',
                gap: '8px',
                width: '170px',
                height: '50px',
                border: '2px solid #90caf9',
                borderRadius: '10px',
                cursor: 'pointer',
              }}
            >
              <input type="radio" checked={!useCamera} onChange={() => setUseCamera(false)} />
              Ø§Ø®ØªÙŠØ§Ø± Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¯ÙŠÙˆ
            </label>
          </div>
        </div>

        <div className="canvas-wrap">
          <video ref={videoRef} playsInline muted style={{ transform: 'scaleX(1)' }} />
          <canvas ref={canvasRef} />
        </div>

        <div className="controls-row" style={{ marginTop: 10 }}>
          <div className="controls">
            <button
              className="btn"
              onClick={startAnalysis}
              disabled={running || !ready}
            >
              <span style={{ marginLeft: "8px" }}>â–¶</span> ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            </button>
            <button
              className="btn secondary"
              onClick={stopAnalysis}
              disabled={!running}
            >
              <span style={{ marginLeft: "8px" }}>â– </span> Ø¥ÙŠÙ‚Ø§Ù + ØªÙ‚Ø±ÙŠØ±
            </button>
            <button
              className="btn secondary"
              onClick={toggleFacing}
              disabled={running}
            >
              <span style={{ marginLeft: "8px" }}>â†»</span> ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ (
              {camFacing === "user" ? "Ø£Ù…Ø§Ù…ÙŠØ©" : "Ø®Ù„ÙÙŠØ©"})
            </button>
          </div>
          {!useCamera && (
            <div style={{ marginLeft: '8px' }}>
              <input type="file" accept="video/*" onChange={handleFile} />
            </div>
          )}
        </div>

        <div className="hint">
          <strong>Ù†ØµØ§Ø¦Ø­ Ù„Ù„ØªØµÙˆÙŠØ±:</strong>
          <ul className="hint-list">
            <li>
              <span className="icon cam">ğŸ“·</span>
              Ø¶Ø¹ Ø§Ù„ÙƒØ§Ù…ÙŠØ±Ø§ Ù…Ù† <strong>Ø§Ù„Ø¬Ø§Ù†Ø¨ (Side view)</strong> Ø¹Ù„Ù‰ Ø¨ÙØ¹Ø¯ <strong>2.5 â€“ 4 Ø£Ù…ØªØ§Ø±</strong>
            </li>
            <li>
              <span className="icon light">ğŸ’¡</span>
              ÙˆÙÙÙ‘Ø± <strong>Ø¥Ø¶Ø§Ø¡Ø© Ø¬ÙŠØ¯Ø© ÙˆÙ…ØªØ¬Ø§Ù†Ø³Ø©</strong> ÙˆØªØ¬Ù†Ù‘Ø¨ Ø§Ù„Ø®Ù„ÙÙŠØ© Ø§Ù„Ù…Ø¶ÙŠØ¦Ø©
            </li>
            <li>
              <span className="icon body">ğŸ‘¤</span>
              Ø§Ø­Ø±Øµ Ø£Ù† <strong>ÙŠØ¸Ù‡Ø± Ø§Ù„Ø¬Ø³Ù… ÙƒØ§Ù…Ù„Ø§Ù‹ Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¥Ø·Ø§Ø± Ø·ÙˆØ§Ù„ Ø§Ù„Ù…Ø´ÙŠ</strong>
            </li>
            <li>
              <span className="icon steps">ğŸ‘£</span>
              <strong>Ø§Ù…Ø´Ù 6 â€“ 10 Ø®Ø·ÙˆØ§Øª</strong> Ø¨Ø³Ø±Ø¹Ø© Ø«Ø§Ø¨ØªØ©
            </li>
          </ul>
        </div>

      </div>
    </div>
  );
}